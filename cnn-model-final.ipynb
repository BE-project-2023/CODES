{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-31T12:51:53.885496Z","iopub.execute_input":"2023-05-31T12:51:53.886652Z","iopub.status.idle":"2023-05-31T12:51:53.901506Z","shell.execute_reply.started":"2023-05-31T12:51:53.886599Z","shell.execute_reply":"2023-05-31T12:51:53.900476Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install --upgrade --no-cache-dir gdown","metadata":{"execution":{"iopub.status.busy":"2023-05-31T12:51:53.903476Z","iopub.execute_input":"2023-05-31T12:51:53.903918Z","iopub.status.idle":"2023-05-31T12:52:06.647896Z","shell.execute_reply.started":"2023-05-31T12:51:53.903884Z","shell.execute_reply":"2023-05-31T12:52:06.646741Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting gdown\n  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.12.0)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.28.2)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from gdown) (1.16.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.64.1)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2023.5.7)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nInstalling collected packages: gdown\nSuccessfully installed gdown-4.7.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!gdown --id 1Ilfihfk2QxOcgikb2ihNO1YakXUCIPMe","metadata":{"execution":{"iopub.status.busy":"2023-05-31T12:52:06.650136Z","iopub.execute_input":"2023-05-31T12:52:06.651227Z","iopub.status.idle":"2023-05-31T12:52:34.700181Z","shell.execute_reply.started":"2023-05-31T12:52:06.651185Z","shell.execute_reply":"2023-05-31T12:52:34.699096Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.10/site-packages/gdown/cli.py:126: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom (uriginal): https://drive.google.com/uc?id=1Ilfihfk2QxOcgikb2ihNO1YakXUCIPMe\nFrom (redirected): https://drive.google.com/uc?id=1Ilfihfk2QxOcgikb2ihNO1YakXUCIPMe&confirm=t&uuid=847ce8be-b61c-4f17-95b1-ab6b9fc212cf\nTo: /kaggle/working/increased data.zip\n100%|██████████████████████████████████████| 1.38G/1.38G [00:25<00:00, 54.7MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"from zipfile import ZipFile\n\nfile_name = \"/kaggle/working/increased data.zip\"\n\nwith ZipFile(file_name, 'r') as zip:\n  zip.extractall()\n  print('done')","metadata":{"execution":{"iopub.status.busy":"2023-05-31T12:52:34.703456Z","iopub.execute_input":"2023-05-31T12:52:34.704528Z","iopub.status.idle":"2023-05-31T12:52:44.156653Z","shell.execute_reply.started":"2023-05-31T12:52:34.704485Z","shell.execute_reply":"2023-05-31T12:52:44.155648Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"done\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport keras\nimport tensorflow as tf\nimport cv2\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import regularizers\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils.np_utils import to_categorical\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n","metadata":{"execution":{"iopub.status.busy":"2023-05-31T12:52:44.158325Z","iopub.execute_input":"2023-05-31T12:52:44.158715Z","iopub.status.idle":"2023-05-31T12:52:52.919013Z","shell.execute_reply.started":"2023-05-31T12:52:44.158682Z","shell.execute_reply":"2023-05-31T12:52:52.917288Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"#get the classnames  programmatically\nimport pathlib\ndata_dir=pathlib.Path(\"/kaggle/working/data/train\")\nclass_names=np.array(sorted([item.name for item in data_dir.glob(\"*\")])) # created a list of class_names from the sub directories\nprint(class_names)","metadata":{"execution":{"iopub.status.busy":"2023-05-31T12:52:52.921018Z","iopub.execute_input":"2023-05-31T12:52:52.921731Z","iopub.status.idle":"2023-05-31T12:52:52.934971Z","shell.execute_reply.started":"2023-05-31T12:52:52.921698Z","shell.execute_reply":"2023-05-31T12:52:52.930086Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"[]\n","output_type":"stream"}]},{"cell_type":"code","source":"#visualize \nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg \nimport random\n\ndef view_random_image(target_dir,target_class):\n  target_folder=target_dir+target_class\n\n  random_image=random.sample(os.listdir(target_folder),1)\n  img=mpimg.imread(target_folder+\"/\"+random_image[0])\n  plt.imshow(img)\n  plt.title(target_class)\n  plt.axis(\"off\");\n\n  print(f\"Image shape : {img.shape}\")\n  return img","metadata":{"execution":{"iopub.status.busy":"2023-05-31T12:52:52.936317Z","iopub.execute_input":"2023-05-31T12:52:52.936849Z","iopub.status.idle":"2023-05-31T12:52:54.290589Z","shell.execute_reply.started":"2023-05-31T12:52:52.936820Z","shell.execute_reply":"2023-05-31T12:52:54.289458Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Define the number of classes in the dataset\nnum_classes = 10\n\ntrain_dir='/kaggle/working/data/train'\ntest_dir='/kaggle/working/data/test'\n\n# Load and preprocess the data\ntrain_datagen = ImageDataGenerator(rescale=1/255.)\ntest_datagen = ImageDataGenerator(rescale=1/255.)\n# Load data in from directories and turn it into batches\ntrain_data = train_datagen.flow_from_directory(train_dir,\n                                               target_size=(224, 224),\n                                               batch_size=32,\n                                               class_mode='categorical') # changed to categorical\n\ntest_data = train_datagen.flow_from_directory(test_dir,\n                                              target_size=(224, 224),\n                                              batch_size=32,\n                                              class_mode='categorical')","metadata":{"execution":{"iopub.status.busy":"2023-05-31T12:52:54.291976Z","iopub.execute_input":"2023-05-31T12:52:54.292303Z","iopub.status.idle":"2023-05-31T12:52:55.007352Z","shell.execute_reply.started":"2023-05-31T12:52:54.292276Z","shell.execute_reply":"2023-05-31T12:52:55.006482Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Found 10495 images belonging to 10 classes.\nFound 3947 images belonging to 10 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"train_datagen_augmented = ImageDataGenerator(rescale=1/255.,\n                                             rotation_range=20, # note: this is an int not a float\n                                             width_shift_range=0.1,\n                                             height_shift_range=0.1,\n                                             zoom_range=0.1,\n                                             horizontal_flip=True)\n\ntrain_data_augmented = train_datagen_augmented.flow_from_directory(train_dir,\n                                                                  target_size=(224, 224),\n                                                                  batch_size=32,\n                                                                  class_mode='categorical')","metadata":{"execution":{"iopub.status.busy":"2023-05-31T12:52:55.008570Z","iopub.execute_input":"2023-05-31T12:52:55.008924Z","iopub.status.idle":"2023-05-31T12:52:55.291482Z","shell.execute_reply.started":"2023-05-31T12:52:55.008892Z","shell.execute_reply":"2023-05-31T12:52:55.290603Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Found 10495 images belonging to 10 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.regularizers import l2\nmodel_26 = Sequential([\n\nConv2D(32, (3,3), activation='relu', input_shape=(224,224,3)),\nAveragePooling2D(pool_size=(2,2)),\n\nConv2D(64, (3,3), activation='relu'),\nAveragePooling2D(pool_size=(2,2)),\n\nConv2D(128, (3,3), activation='relu'),\nAveragePooling2D(pool_size=(2,2)),\n    \nConv2D(256, (3,3), activation='relu'),\nAveragePooling2D(pool_size=(2,2)),\n\n\n\n# Flatten layer\nFlatten(),\n\n# Dense layers\nDense(512, activation='relu'),\nDropout(0.35),\n\nDense(10, activation='softmax')])\n\nmodel_26.compile(loss=\"categorical_crossentropy\",\n                optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n                metrics=[\"accuracy\"]) \n","metadata":{"execution":{"iopub.status.busy":"2023-05-31T12:53:08.299502Z","iopub.execute_input":"2023-05-31T12:53:08.299850Z","iopub.status.idle":"2023-05-31T12:53:11.212566Z","shell.execute_reply.started":"2023-05-31T12:53:08.299821Z","shell.execute_reply":"2023-05-31T12:53:11.211651Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model_26.summary()","metadata":{"execution":{"iopub.status.busy":"2023-05-31T12:53:21.059623Z","iopub.execute_input":"2023-05-31T12:53:21.059982Z","iopub.status.idle":"2023-05-31T12:53:21.096838Z","shell.execute_reply.started":"2023-05-31T12:53:21.059951Z","shell.execute_reply":"2023-05-31T12:53:21.095499Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 222, 222, 32)      896       \n                                                                 \n average_pooling2d (AverageP  (None, 111, 111, 32)     0         \n ooling2D)                                                       \n                                                                 \n conv2d_1 (Conv2D)           (None, 109, 109, 64)      18496     \n                                                                 \n average_pooling2d_1 (Averag  (None, 54, 54, 64)       0         \n ePooling2D)                                                     \n                                                                 \n conv2d_2 (Conv2D)           (None, 52, 52, 128)       73856     \n                                                                 \n average_pooling2d_2 (Averag  (None, 26, 26, 128)      0         \n ePooling2D)                                                     \n                                                                 \n conv2d_3 (Conv2D)           (None, 24, 24, 256)       295168    \n                                                                 \n average_pooling2d_3 (Averag  (None, 12, 12, 256)      0         \n ePooling2D)                                                     \n                                                                 \n flatten (Flatten)           (None, 36864)             0         \n                                                                 \n dense (Dense)               (None, 512)               18874880  \n                                                                 \n dropout (Dropout)           (None, 512)               0         \n                                                                 \n dense_1 (Dense)             (None, 10)                5130      \n                                                                 \n=================================================================\nTotal params: 19,268,426\nTrainable params: 19,268,426\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model_26.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-05-31T12:53:52.709122Z","iopub.execute_input":"2023-05-31T12:53:52.709467Z","iopub.status.idle":"2023-05-31T12:53:52.723015Z","shell.execute_reply.started":"2023-05-31T12:53:52.709438Z","shell.execute_reply":"2023-05-31T12:53:52.721982Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Train the model\nhistory = model_26.fit(\n    train_data_augmented,\n    steps_per_epoch=len(train_data_augmented),\n    epochs=200,\n    validation_data=test_data,\n    validation_steps=len(test_data)\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-31T12:54:11.379442Z","iopub.execute_input":"2023-05-31T12:54:11.379877Z","iopub.status.idle":"2023-05-31T22:23:08.589238Z","shell.execute_reply.started":"2023-05-31T12:54:11.379842Z","shell.execute_reply":"2023-05-31T22:23:08.588193Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Epoch 1/200\n328/328 [==============================] - 156s 446ms/step - loss: 2.1708 - accuracy: 0.1840 - val_loss: 2.1387 - val_accuracy: 0.1996\nEpoch 2/200\n328/328 [==============================] - 149s 453ms/step - loss: 2.0674 - accuracy: 0.2367 - val_loss: 2.0477 - val_accuracy: 0.2539\nEpoch 3/200\n328/328 [==============================] - 143s 437ms/step - loss: 2.0154 - accuracy: 0.2581 - val_loss: 2.0172 - val_accuracy: 0.2734\nEpoch 4/200\n328/328 [==============================] - 145s 443ms/step - loss: 1.9656 - accuracy: 0.2806 - val_loss: 1.9568 - val_accuracy: 0.2888\nEpoch 5/200\n328/328 [==============================] - 146s 445ms/step - loss: 1.9171 - accuracy: 0.3036 - val_loss: 1.9003 - val_accuracy: 0.3185\nEpoch 6/200\n328/328 [==============================] - 144s 438ms/step - loss: 1.8902 - accuracy: 0.3222 - val_loss: 1.8648 - val_accuracy: 0.3398\nEpoch 7/200\n328/328 [==============================] - 145s 441ms/step - loss: 1.8564 - accuracy: 0.3313 - val_loss: 1.8254 - val_accuracy: 0.3570\nEpoch 8/200\n328/328 [==============================] - 145s 441ms/step - loss: 1.8302 - accuracy: 0.3405 - val_loss: 1.8349 - val_accuracy: 0.3456\nEpoch 9/200\n328/328 [==============================] - 147s 448ms/step - loss: 1.7990 - accuracy: 0.3543 - val_loss: 1.8716 - val_accuracy: 0.3496\nEpoch 10/200\n328/328 [==============================] - 144s 440ms/step - loss: 1.7794 - accuracy: 0.3623 - val_loss: 1.7457 - val_accuracy: 0.3805\nEpoch 11/200\n328/328 [==============================] - 145s 442ms/step - loss: 1.7537 - accuracy: 0.3697 - val_loss: 1.7391 - val_accuracy: 0.3932\nEpoch 12/200\n328/328 [==============================] - 146s 447ms/step - loss: 1.7271 - accuracy: 0.3829 - val_loss: 1.7586 - val_accuracy: 0.3851\nEpoch 13/200\n328/328 [==============================] - 148s 450ms/step - loss: 1.7102 - accuracy: 0.3884 - val_loss: 1.7058 - val_accuracy: 0.3947\nEpoch 14/200\n328/328 [==============================] - 149s 453ms/step - loss: 1.6854 - accuracy: 0.4027 - val_loss: 1.7115 - val_accuracy: 0.4087\nEpoch 15/200\n328/328 [==============================] - 146s 446ms/step - loss: 1.6544 - accuracy: 0.4126 - val_loss: 1.6495 - val_accuracy: 0.4368\nEpoch 16/200\n328/328 [==============================] - 146s 445ms/step - loss: 1.6406 - accuracy: 0.4190 - val_loss: 1.6308 - val_accuracy: 0.4375\nEpoch 17/200\n328/328 [==============================] - 147s 447ms/step - loss: 1.6349 - accuracy: 0.4201 - val_loss: 1.6736 - val_accuracy: 0.4196\nEpoch 18/200\n328/328 [==============================] - 146s 445ms/step - loss: 1.5883 - accuracy: 0.4359 - val_loss: 1.6529 - val_accuracy: 0.4325\nEpoch 19/200\n328/328 [==============================] - 143s 436ms/step - loss: 1.5890 - accuracy: 0.4348 - val_loss: 1.5851 - val_accuracy: 0.4502\nEpoch 20/200\n328/328 [==============================] - 144s 438ms/step - loss: 1.5684 - accuracy: 0.4475 - val_loss: 1.5548 - val_accuracy: 0.4634\nEpoch 21/200\n328/328 [==============================] - 146s 446ms/step - loss: 1.5598 - accuracy: 0.4472 - val_loss: 1.5708 - val_accuracy: 0.4583\nEpoch 22/200\n328/328 [==============================] - 147s 448ms/step - loss: 1.5231 - accuracy: 0.4577 - val_loss: 1.5456 - val_accuracy: 0.4728\nEpoch 23/200\n328/328 [==============================] - 145s 443ms/step - loss: 1.4935 - accuracy: 0.4708 - val_loss: 1.5413 - val_accuracy: 0.4611\nEpoch 24/200\n328/328 [==============================] - 145s 442ms/step - loss: 1.4864 - accuracy: 0.4733 - val_loss: 1.5416 - val_accuracy: 0.4930\nEpoch 25/200\n328/328 [==============================] - 144s 440ms/step - loss: 1.4593 - accuracy: 0.4874 - val_loss: 1.4866 - val_accuracy: 0.4981\nEpoch 26/200\n328/328 [==============================] - 150s 456ms/step - loss: 1.4471 - accuracy: 0.4926 - val_loss: 1.4919 - val_accuracy: 0.5095\nEpoch 27/200\n328/328 [==============================] - 144s 440ms/step - loss: 1.4288 - accuracy: 0.5012 - val_loss: 1.5340 - val_accuracy: 0.4859\n328/328 [==============================] - 146s 444ms/step - loss: 1.4069 - accuracy: 0.5033 - val_loss: 1.4622 - val_accuracy: 0.5098\nEpoch 29/200\n328/328 [==============================] - 143s 437ms/step - loss: 1.3901 - accuracy: 0.5020 - val_loss: 1.4827 - val_accuracy: 0.5212\nEpoch 30/200\n328/328 [==============================] - 145s 442ms/step - loss: 1.3814 - accuracy: 0.5152 - val_loss: 1.4282 - val_accuracy: 0.5224\nEpoch 31/200\n328/328 [==============================] - 148s 452ms/step - loss: 1.3565 - accuracy: 0.5208 - val_loss: 1.4330 - val_accuracy: 0.5429\nEpoch 32/200\n328/328 [==============================] - 150s 458ms/step - loss: 1.3413 - accuracy: 0.5202 - val_loss: 1.3941 - val_accuracy: 0.5432\nEpoch 33/200\n328/328 [==============================] - 147s 449ms/step - loss: 1.3392 - accuracy: 0.5249 - val_loss: 1.4225 - val_accuracy: 0.5389\nEpoch 34/200\n328/328 [==============================] - 146s 446ms/step - loss: 1.3079 - accuracy: 0.5299 - val_loss: 1.4193 - val_accuracy: 0.5404\nEpoch 35/200\n328/328 [==============================] - 148s 450ms/step - loss: 1.2948 - accuracy: 0.5371 - val_loss: 1.4096 - val_accuracy: 0.5402\nEpoch 36/200\n328/328 [==============================] - 149s 455ms/step - loss: 1.2752 - accuracy: 0.5508 - val_loss: 1.4054 - val_accuracy: 0.5533\nEpoch 37/200\n328/328 [==============================] - 145s 442ms/step - loss: 1.2531 - accuracy: 0.5640 - val_loss: 1.3541 - val_accuracy: 0.5584\nEpoch 38/200\n328/328 [==============================] - 145s 441ms/step - loss: 1.2542 - accuracy: 0.5643 - val_loss: 1.3835 - val_accuracy: 0.5483\nEpoch 39/200\n328/328 [==============================] - 143s 437ms/step - loss: 1.2414 - accuracy: 0.5607 - val_loss: 1.3430 - val_accuracy: 0.5711\nEpoch 40/200\n328/328 [==============================] - 146s 446ms/step - loss: 1.2294 - accuracy: 0.5683 - val_loss: 1.3789 - val_accuracy: 0.5604\nEpoch 41/200\n328/328 [==============================] - 146s 444ms/step - loss: 1.2115 - accuracy: 0.5726 - val_loss: 1.3875 - val_accuracy: 0.5511\nEpoch 42/200\n328/328 [==============================] - 145s 442ms/step - loss: 1.2129 - accuracy: 0.5692 - val_loss: 1.3322 - val_accuracy: 0.5617\nEpoch 43/200\n328/328 [==============================] - 144s 440ms/step - loss: 1.1882 - accuracy: 0.5765 - val_loss: 1.2996 - val_accuracy: 0.5825\nEpoch 44/200\n328/328 [==============================] - 145s 444ms/step - loss: 1.1622 - accuracy: 0.5900 - val_loss: 1.3537 - val_accuracy: 0.5820\nEpoch 45/200\n328/328 [==============================] - 145s 443ms/step - loss: 1.1811 - accuracy: 0.5842 - val_loss: 1.3518 - val_accuracy: 0.5668\nEpoch 46/200\n328/328 [==============================] - 146s 445ms/step - loss: 1.1449 - accuracy: 0.5964 - val_loss: 1.2943 - val_accuracy: 0.5961\nEpoch 47/200\n328/328 [==============================] - 144s 440ms/step - loss: 1.1432 - accuracy: 0.5978 - val_loss: 1.2527 - val_accuracy: 0.5979\nEpoch 48/200\n328/328 [==============================] - 145s 441ms/step - loss: 1.1164 - accuracy: 0.6070 - val_loss: 1.3080 - val_accuracy: 0.5929\nEpoch 49/200\n328/328 [==============================] - 145s 443ms/step - loss: 1.1132 - accuracy: 0.6085 - val_loss: 1.2613 - val_accuracy: 0.6053\nEpoch 50/200\n328/328 [==============================] - 145s 443ms/step - loss: 1.1165 - accuracy: 0.6096 - val_loss: 1.2889 - val_accuracy: 0.6043\nEpoch 51/200\n328/328 [==============================] - 145s 440ms/step - loss: 1.0993 - accuracy: 0.6051 - val_loss: 1.2544 - val_accuracy: 0.6088\nEpoch 52/200\n328/328 [==============================] - 146s 446ms/step - loss: 1.0784 - accuracy: 0.6193 - val_loss: 1.2757 - val_accuracy: 0.6154\nEpoch 53/200\n328/328 [==============================] - 147s 447ms/step - loss: 1.0829 - accuracy: 0.6199 - val_loss: 1.2737 - val_accuracy: 0.6063\nEpoch 54/200\n328/328 [==============================] - 144s 438ms/step - loss: 1.0679 - accuracy: 0.6259 - val_loss: 1.3004 - val_accuracy: 0.5989\nEpoch 55/200\n328/328 [==============================] - 145s 441ms/step - loss: 1.0566 - accuracy: 0.6250 - val_loss: 1.2624 - val_accuracy: 0.6139\nEpoch 56/200\n328/328 [==============================] - 146s 444ms/step - loss: 1.0394 - accuracy: 0.6434 - val_loss: 1.2729 - val_accuracy: 0.6225\nEpoch 57/200\n328/328 [==============================] - 145s 443ms/step - loss: 1.0343 - accuracy: 0.6327 - val_loss: 1.2544 - val_accuracy: 0.6144\nEpoch 58/200\n328/328 [==============================] - 144s 438ms/step - loss: 1.0390 - accuracy: 0.6305 - val_loss: 1.2751 - val_accuracy: 0.6184\nEpoch 59/200\n328/328 [==============================] - 149s 455ms/step - loss: 1.0261 - accuracy: 0.6396 - val_loss: 1.2304 - val_accuracy: 0.6372\nEpoch 60/200\n328/328 [==============================] - 146s 444ms/step - loss: 1.0068 - accuracy: 0.6475 - val_loss: 1.3067 - val_accuracy: 0.6055\nEpoch 61/200\n328/328 [==============================] - 148s 450ms/step - loss: 1.0028 - accuracy: 0.6483 - val_loss: 1.3042 - val_accuracy: 0.6192\nEpoch 62/200\n328/328 [==============================] - 146s 445ms/step - loss: 0.9955 - accuracy: 0.6474 - val_loss: 1.2473 - val_accuracy: 0.6263\nEpoch 63/200\n328/328 [==============================] - 144s 440ms/step - loss: 0.9868 - accuracy: 0.6470 - val_loss: 1.2363 - val_accuracy: 0.6243\nEpoch 64/200\n328/328 [==============================] - 150s 457ms/step - loss: 0.9892 - accuracy: 0.6539 - val_loss: 1.2431 - val_accuracy: 0.6369\nEpoch 65/200\n328/328 [==============================] - 149s 454ms/step - loss: 0.9729 - accuracy: 0.6619 - val_loss: 1.2752 - val_accuracy: 0.6367\nEpoch 66/200\n328/328 [==============================] - 145s 443ms/step - loss: 0.9694 - accuracy: 0.6595 - val_loss: 1.3129 - val_accuracy: 0.6230\nEpoch 67/200\n328/328 [==============================] - 143s 436ms/step - loss: 0.9431 - accuracy: 0.6684 - val_loss: 1.2745 - val_accuracy: 0.6428\nEpoch 68/200\n328/328 [==============================] - 146s 444ms/step - loss: 0.9320 - accuracy: 0.6684 - val_loss: 1.2988 - val_accuracy: 0.6481\nEpoch 69/200\n328/328 [==============================] - 145s 441ms/step - loss: 0.9273 - accuracy: 0.6761 - val_loss: 1.1978 - val_accuracy: 0.6651\nEpoch 70/200\n328/328 [==============================] - 147s 447ms/step - loss: 0.9208 - accuracy: 0.6778 - val_loss: 1.3019 - val_accuracy: 0.6347\nEpoch 71/200\n328/328 [==============================] - 146s 446ms/step - loss: 0.9241 - accuracy: 0.6717 - val_loss: 1.2337 - val_accuracy: 0.6486\nEpoch 72/200\n328/328 [==============================] - 145s 443ms/step - loss: 0.9094 - accuracy: 0.6808 - val_loss: 1.2593 - val_accuracy: 0.6433\nEpoch 73/200\n328/328 [==============================] - 145s 443ms/step - loss: 0.9007 - accuracy: 0.6838 - val_loss: 1.3318 - val_accuracy: 0.6354\nEpoch 74/200\n328/328 [==============================] - 147s 447ms/step - loss: 0.9007 - accuracy: 0.6824 - val_loss: 1.3475 - val_accuracy: 0.6296\nEpoch 75/200\n328/328 [==============================] - 148s 451ms/step - loss: 0.8939 - accuracy: 0.6894 - val_loss: 1.2394 - val_accuracy: 0.6580\nEpoch 76/200\n328/328 [==============================] - 148s 452ms/step - loss: 0.8951 - accuracy: 0.6817 - val_loss: 1.1574 - val_accuracy: 0.6630\nEpoch 77/200\n328/328 [==============================] - 146s 447ms/step - loss: 0.8719 - accuracy: 0.6919 - val_loss: 1.3179 - val_accuracy: 0.6519\nEpoch 78/200\n328/328 [==============================] - 142s 433ms/step - loss: 0.8832 - accuracy: 0.6946 - val_loss: 1.2136 - val_accuracy: 0.6544\nEpoch 79/200\n328/328 [==============================] - 147s 449ms/step - loss: 0.8633 - accuracy: 0.6966 - val_loss: 1.2634 - val_accuracy: 0.6580\nEpoch 80/200\n328/328 [==============================] - 146s 446ms/step - loss: 0.8734 - accuracy: 0.6908 - val_loss: 1.2507 - val_accuracy: 0.6554\nEpoch 81/200\n328/328 [==============================] - 148s 450ms/step - loss: 0.8611 - accuracy: 0.6963 - val_loss: 1.2621 - val_accuracy: 0.6562\nEpoch 82/200\n328/328 [==============================] - 146s 445ms/step - loss: 0.8666 - accuracy: 0.6948 - val_loss: 1.1959 - val_accuracy: 0.6661\nEpoch 83/200\n328/328 [==============================] - 144s 439ms/step - loss: 0.8572 - accuracy: 0.6960 - val_loss: 1.3346 - val_accuracy: 0.6564\nEpoch 84/200\n328/328 [==============================] - 146s 446ms/step - loss: 0.8583 - accuracy: 0.6993 - val_loss: 1.2731 - val_accuracy: 0.6532\nEpoch 85/200\n328/328 [==============================] - 150s 457ms/step - loss: 0.8332 - accuracy: 0.7061 - val_loss: 1.2694 - val_accuracy: 0.6572\nEpoch 86/200\n328/328 [==============================] - 147s 447ms/step - loss: 0.8396 - accuracy: 0.7041 - val_loss: 1.2437 - val_accuracy: 0.6640\nEpoch 87/200\n328/328 [==============================] - 146s 445ms/step - loss: 0.8425 - accuracy: 0.7122 - val_loss: 1.3369 - val_accuracy: 0.6402\nEpoch 88/200\n328/328 [==============================] - 147s 448ms/step - loss: 0.8105 - accuracy: 0.7162 - val_loss: 1.2771 - val_accuracy: 0.6529\nEpoch 89/200\n328/328 [==============================] - 146s 445ms/step - loss: 0.8086 - accuracy: 0.7181 - val_loss: 1.3478 - val_accuracy: 0.6572\nEpoch 90/200\n328/328 [==============================] - 146s 444ms/step - loss: 0.8285 - accuracy: 0.7103 - val_loss: 1.2472 - val_accuracy: 0.6638\nEpoch 91/200\n328/328 [==============================] - 145s 441ms/step - loss: 0.8183 - accuracy: 0.7110 - val_loss: 1.2358 - val_accuracy: 0.6686\nEpoch 92/200\n328/328 [==============================] - 146s 444ms/step - loss: 0.8191 - accuracy: 0.7200 - val_loss: 1.3887 - val_accuracy: 0.6496\nEpoch 93/200\n328/328 [==============================] - 146s 445ms/step - loss: 0.7801 - accuracy: 0.7244 - val_loss: 1.2269 - val_accuracy: 0.6793\nEpoch 94/200\n328/328 [==============================] - 145s 441ms/step - loss: 0.8079 - accuracy: 0.7170 - val_loss: 1.2510 - val_accuracy: 0.6681\nEpoch 95/200\n328/328 [==============================] - 153s 465ms/step - loss: 0.7910 - accuracy: 0.7295 - val_loss: 1.2578 - val_accuracy: 0.6711\nEpoch 96/200\n328/328 [==============================] - 146s 444ms/step - loss: 0.7743 - accuracy: 0.7304 - val_loss: 1.2139 - val_accuracy: 0.6744\nEpoch 97/200\n328/328 [==============================] - 147s 448ms/step - loss: 0.7870 - accuracy: 0.7229 - val_loss: 1.3379 - val_accuracy: 0.6309\nEpoch 98/200\n328/328 [==============================] - 145s 440ms/step - loss: 0.7917 - accuracy: 0.7208 - val_loss: 1.2842 - val_accuracy: 0.6696\nEpoch 99/200\n328/328 [==============================] - 145s 441ms/step - loss: 0.7813 - accuracy: 0.7263 - val_loss: 1.2542 - val_accuracy: 0.6678\nEpoch 100/200\n328/328 [==============================] - 145s 442ms/step - loss: 0.7736 - accuracy: 0.7287 - val_loss: 1.2170 - val_accuracy: 0.6757\nEpoch 101/200\n328/328 [==============================] - 146s 446ms/step - loss: 0.7638 - accuracy: 0.7340 - val_loss: 1.2497 - val_accuracy: 0.6777\nEpoch 102/200\n328/328 [==============================] - 144s 440ms/step - loss: 0.7532 - accuracy: 0.7385 - val_loss: 1.3185 - val_accuracy: 0.6780\nEpoch 103/200\n328/328 [==============================] - 147s 448ms/step - loss: 0.7608 - accuracy: 0.7325 - val_loss: 1.2478 - val_accuracy: 0.6749\nEpoch 104/200\n328/328 [==============================] - 145s 442ms/step - loss: 0.7762 - accuracy: 0.7279 - val_loss: 1.2412 - val_accuracy: 0.6782\nEpoch 105/200\n328/328 [==============================] - 145s 442ms/step - loss: 0.7333 - accuracy: 0.7462 - val_loss: 1.3231 - val_accuracy: 0.6716\nEpoch 106/200\n328/328 [==============================] - 144s 439ms/step - loss: 0.7831 - accuracy: 0.7272 - val_loss: 1.3336 - val_accuracy: 0.6562\nEpoch 107/200\n328/328 [==============================] - 144s 439ms/step - loss: 0.7526 - accuracy: 0.7363 - val_loss: 1.2372 - val_accuracy: 0.6836\nEpoch 108/200\n328/328 [==============================] - 146s 443ms/step - loss: 0.7347 - accuracy: 0.7407 - val_loss: 1.2111 - val_accuracy: 0.6841\nEpoch 109/200\n328/328 [==============================] - 145s 441ms/step - loss: 0.7187 - accuracy: 0.7476 - val_loss: 1.2130 - val_accuracy: 0.6754\nEpoch 110/200\n328/328 [==============================] - 148s 450ms/step - loss: 0.7200 - accuracy: 0.7487 - val_loss: 1.2694 - val_accuracy: 0.6732\nEpoch 111/200\n328/328 [==============================] - 146s 444ms/step - loss: 0.7294 - accuracy: 0.7447 - val_loss: 1.3032 - val_accuracy: 0.6805\nEpoch 112/200\n328/328 [==============================] - 145s 442ms/step - loss: 0.7387 - accuracy: 0.7455 - val_loss: 1.3058 - val_accuracy: 0.6709\nEpoch 113/200\n328/328 [==============================] - 146s 446ms/step - loss: 0.7245 - accuracy: 0.7495 - val_loss: 1.2082 - val_accuracy: 0.6820\nEpoch 114/200\n328/328 [==============================] - 145s 443ms/step - loss: 0.7273 - accuracy: 0.7461 - val_loss: 1.2131 - val_accuracy: 0.6800\nEpoch 115/200\n328/328 [==============================] - 144s 440ms/step - loss: 0.7184 - accuracy: 0.7499 - val_loss: 1.3727 - val_accuracy: 0.6724\nEpoch 116/200\n328/328 [==============================] - 145s 443ms/step - loss: 0.7021 - accuracy: 0.7545 - val_loss: 1.2947 - val_accuracy: 0.6907\nEpoch 117/200\n328/328 [==============================] - 144s 441ms/step - loss: 0.7005 - accuracy: 0.7585 - val_loss: 1.3743 - val_accuracy: 0.6790\nEpoch 118/200\n328/328 [==============================] - 144s 438ms/step - loss: 0.7023 - accuracy: 0.7576 - val_loss: 1.3917 - val_accuracy: 0.6841\nEpoch 119/200\n328/328 [==============================] - 144s 439ms/step - loss: 0.6899 - accuracy: 0.7571 - val_loss: 1.3062 - val_accuracy: 0.6939\nEpoch 120/200\n328/328 [==============================] - 145s 441ms/step - loss: 0.6896 - accuracy: 0.7581 - val_loss: 1.4759 - val_accuracy: 0.6678\nEpoch 121/200\n328/328 [==============================] - 143s 436ms/step - loss: 0.6846 - accuracy: 0.7588 - val_loss: 1.4424 - val_accuracy: 0.6701\nEpoch 122/200\n328/328 [==============================] - 143s 436ms/step - loss: 0.6956 - accuracy: 0.7544 - val_loss: 1.3242 - val_accuracy: 0.6787\nEpoch 123/200\n328/328 [==============================] - 145s 442ms/step - loss: 0.6706 - accuracy: 0.7664 - val_loss: 1.2710 - val_accuracy: 0.6879\nEpoch 124/200\n328/328 [==============================] - 145s 443ms/step - loss: 0.6789 - accuracy: 0.7692 - val_loss: 1.3966 - val_accuracy: 0.6851\nEpoch 125/200\n328/328 [==============================] - 147s 447ms/step - loss: 0.6829 - accuracy: 0.7641 - val_loss: 1.2612 - val_accuracy: 0.6795\nEpoch 126/200\n328/328 [==============================] - 146s 445ms/step - loss: 0.6898 - accuracy: 0.7620 - val_loss: 1.2922 - val_accuracy: 0.6871\nEpoch 127/200\n328/328 [==============================] - 146s 446ms/step - loss: 0.6652 - accuracy: 0.7670 - val_loss: 1.3125 - val_accuracy: 0.6861\nEpoch 128/200\n328/328 [==============================] - 146s 444ms/step - loss: 0.6803 - accuracy: 0.7591 - val_loss: 1.3710 - val_accuracy: 0.6820\nEpoch 129/200\n328/328 [==============================] - 147s 448ms/step - loss: 0.6563 - accuracy: 0.7703 - val_loss: 1.3305 - val_accuracy: 0.6919\nEpoch 130/200\n328/328 [==============================] - 145s 444ms/step - loss: 0.6766 - accuracy: 0.7646 - val_loss: 1.2797 - val_accuracy: 0.7028\nEpoch 131/200\n328/328 [==============================] - 147s 448ms/step - loss: 0.6510 - accuracy: 0.7737 - val_loss: 1.3171 - val_accuracy: 0.6962\nEpoch 132/200\n328/328 [==============================] - 147s 447ms/step - loss: 0.6417 - accuracy: 0.7722 - val_loss: 1.3824 - val_accuracy: 0.6952\nEpoch 133/200\n328/328 [==============================] - 146s 445ms/step - loss: 0.6409 - accuracy: 0.7761 - val_loss: 1.2567 - val_accuracy: 0.6967\nEpoch 134/200\n328/328 [==============================] - 148s 451ms/step - loss: 0.6522 - accuracy: 0.7717 - val_loss: 1.3784 - val_accuracy: 0.6861\nEpoch 135/200\n328/328 [==============================] - 146s 445ms/step - loss: 0.6320 - accuracy: 0.7769 - val_loss: 1.3781 - val_accuracy: 0.6825\nEpoch 136/200\n328/328 [==============================] - 146s 445ms/step - loss: 0.6583 - accuracy: 0.7727 - val_loss: 1.3229 - val_accuracy: 0.6904\nEpoch 137/200\n328/328 [==============================] - 148s 450ms/step - loss: 0.6434 - accuracy: 0.7792 - val_loss: 1.3162 - val_accuracy: 0.6851\nEpoch 138/200\n328/328 [==============================] - 148s 453ms/step - loss: 0.6464 - accuracy: 0.7725 - val_loss: 1.3942 - val_accuracy: 0.6841\nEpoch 139/200\n328/328 [==============================] - 148s 451ms/step - loss: 0.6230 - accuracy: 0.7807 - val_loss: 1.2895 - val_accuracy: 0.6848\nEpoch 140/200\n328/328 [==============================] - 148s 450ms/step - loss: 0.6164 - accuracy: 0.7857 - val_loss: 1.3293 - val_accuracy: 0.6884\nEpoch 141/200\n328/328 [==============================] - 151s 459ms/step - loss: 0.6208 - accuracy: 0.7829 - val_loss: 1.3800 - val_accuracy: 0.6932\nEpoch 142/200\n328/328 [==============================] - 146s 444ms/step - loss: 0.6443 - accuracy: 0.7770 - val_loss: 1.3068 - val_accuracy: 0.7031\nEpoch 143/200\n328/328 [==============================] - 145s 442ms/step - loss: 0.6141 - accuracy: 0.7849 - val_loss: 1.2916 - val_accuracy: 0.6924\nEpoch 144/200\n328/328 [==============================] - 153s 468ms/step - loss: 0.6102 - accuracy: 0.7931 - val_loss: 1.3582 - val_accuracy: 0.6919\nEpoch 145/200\n328/328 [==============================] - 144s 440ms/step - loss: 0.6299 - accuracy: 0.7793 - val_loss: 1.3720 - val_accuracy: 0.6896\nEpoch 146/200\n328/328 [==============================] - 146s 444ms/step - loss: 0.6200 - accuracy: 0.7833 - val_loss: 1.3378 - val_accuracy: 0.6904\nEpoch 147/200\n328/328 [==============================] - 145s 441ms/step - loss: 0.6134 - accuracy: 0.7854 - val_loss: 1.2524 - val_accuracy: 0.6983\nEpoch 148/200\n328/328 [==============================] - 146s 444ms/step - loss: 0.6159 - accuracy: 0.7875 - val_loss: 1.3137 - val_accuracy: 0.7038\nEpoch 149/200\n328/328 [==============================] - 144s 440ms/step - loss: 0.6151 - accuracy: 0.7899 - val_loss: 1.3734 - val_accuracy: 0.6881\nEpoch 150/200\n328/328 [==============================] - 143s 437ms/step - loss: 0.6125 - accuracy: 0.7890 - val_loss: 1.4267 - val_accuracy: 0.6808\nEpoch 151/200\n328/328 [==============================] - 145s 443ms/step - loss: 0.6179 - accuracy: 0.7847 - val_loss: 1.3820 - val_accuracy: 0.6955\nEpoch 152/200\n328/328 [==============================] - 146s 445ms/step - loss: 0.6077 - accuracy: 0.7882 - val_loss: 1.2696 - val_accuracy: 0.6939\nEpoch 153/200\n328/328 [==============================] - 145s 441ms/step - loss: 0.6180 - accuracy: 0.7852 - val_loss: 1.2741 - val_accuracy: 0.7018\nEpoch 154/200\n328/328 [==============================] - 144s 439ms/step - loss: 0.5868 - accuracy: 0.7955 - val_loss: 1.3731 - val_accuracy: 0.6970\nEpoch 155/200\n328/328 [==============================] - 144s 440ms/step - loss: 0.6020 - accuracy: 0.7876 - val_loss: 1.3811 - val_accuracy: 0.6942\nEpoch 156/200\n328/328 [==============================] - 143s 436ms/step - loss: 0.6092 - accuracy: 0.7880 - val_loss: 1.4093 - val_accuracy: 0.7086\nEpoch 157/200\n328/328 [==============================] - 145s 443ms/step - loss: 0.5986 - accuracy: 0.7885 - val_loss: 1.3561 - val_accuracy: 0.7091\nEpoch 158/200\n328/328 [==============================] - 145s 441ms/step - loss: 0.5916 - accuracy: 0.7987 - val_loss: 1.3772 - val_accuracy: 0.7018\nEpoch 159/200\n328/328 [==============================] - 145s 443ms/step - loss: 0.5661 - accuracy: 0.8008 - val_loss: 1.3748 - val_accuracy: 0.7003\nEpoch 160/200\n328/328 [==============================] - 146s 445ms/step - loss: 0.5715 - accuracy: 0.8024 - val_loss: 1.3731 - val_accuracy: 0.7056\nEpoch 161/200\n328/328 [==============================] - 143s 437ms/step - loss: 0.5855 - accuracy: 0.7953 - val_loss: 1.3384 - val_accuracy: 0.7015\nEpoch 162/200\n328/328 [==============================] - 144s 440ms/step - loss: 0.5767 - accuracy: 0.7984 - val_loss: 1.3433 - val_accuracy: 0.6960\nEpoch 163/200\n328/328 [==============================] - 145s 441ms/step - loss: 0.6057 - accuracy: 0.7914 - val_loss: 1.4681 - val_accuracy: 0.6990\nEpoch 164/200\n328/328 [==============================] - 143s 436ms/step - loss: 0.5808 - accuracy: 0.8009 - val_loss: 1.3741 - val_accuracy: 0.6876\nEpoch 165/200\n328/328 [==============================] - 146s 446ms/step - loss: 0.5684 - accuracy: 0.8066 - val_loss: 1.3150 - val_accuracy: 0.7081\nEpoch 166/200\n328/328 [==============================] - 145s 443ms/step - loss: 0.5616 - accuracy: 0.8017 - val_loss: 1.3759 - val_accuracy: 0.6945\nEpoch 167/200\n328/328 [==============================] - 144s 440ms/step - loss: 0.5602 - accuracy: 0.8034 - val_loss: 1.3807 - val_accuracy: 0.7066\nEpoch 168/200\n328/328 [==============================] - 145s 441ms/step - loss: 0.5766 - accuracy: 0.8021 - val_loss: 1.3991 - val_accuracy: 0.7000\nEpoch 169/200\n328/328 [==============================] - 144s 440ms/step - loss: 0.5677 - accuracy: 0.8019 - val_loss: 1.4188 - val_accuracy: 0.7069\nEpoch 170/200\n328/328 [==============================] - 144s 439ms/step - loss: 0.5725 - accuracy: 0.8019 - val_loss: 1.3771 - val_accuracy: 0.7061\nEpoch 171/200\n328/328 [==============================] - 145s 441ms/step - loss: 0.5785 - accuracy: 0.8026 - val_loss: 1.3480 - val_accuracy: 0.7099\nEpoch 172/200\n328/328 [==============================] - 144s 439ms/step - loss: 0.5739 - accuracy: 0.8021 - val_loss: 1.3954 - val_accuracy: 0.7041\nEpoch 173/200\n328/328 [==============================] - 145s 442ms/step - loss: 0.5735 - accuracy: 0.8051 - val_loss: 1.4028 - val_accuracy: 0.6871\nEpoch 174/200\n328/328 [==============================] - 143s 437ms/step - loss: 0.5364 - accuracy: 0.8105 - val_loss: 1.4070 - val_accuracy: 0.7036\nEpoch 175/200\n328/328 [==============================] - 143s 437ms/step - loss: 0.5561 - accuracy: 0.8055 - val_loss: 1.4734 - val_accuracy: 0.6945\nEpoch 176/200\n328/328 [==============================] - 145s 441ms/step - loss: 0.5530 - accuracy: 0.8066 - val_loss: 1.4573 - val_accuracy: 0.6942\nEpoch 177/200\n328/328 [==============================] - 145s 441ms/step - loss: 0.5463 - accuracy: 0.8098 - val_loss: 1.4861 - val_accuracy: 0.6998\nEpoch 178/200\n328/328 [==============================] - 145s 443ms/step - loss: 0.5565 - accuracy: 0.8109 - val_loss: 1.3814 - val_accuracy: 0.7079\nEpoch 179/200\n328/328 [==============================] - 145s 442ms/step - loss: 0.5554 - accuracy: 0.8066 - val_loss: 1.3639 - val_accuracy: 0.7079\nEpoch 180/200\n328/328 [==============================] - 143s 437ms/step - loss: 0.5537 - accuracy: 0.8106 - val_loss: 1.5070 - val_accuracy: 0.7010\nEpoch 181/200\n328/328 [==============================] - 144s 440ms/step - loss: 0.5475 - accuracy: 0.8076 - val_loss: 1.3330 - val_accuracy: 0.7122\nEpoch 182/200\n328/328 [==============================] - 144s 438ms/step - loss: 0.5605 - accuracy: 0.8056 - val_loss: 1.4631 - val_accuracy: 0.7102\nEpoch 183/200\n328/328 [==============================] - 144s 439ms/step - loss: 0.5594 - accuracy: 0.8070 - val_loss: 1.3832 - val_accuracy: 0.7102\nEpoch 184/200\n328/328 [==============================] - 146s 446ms/step - loss: 0.5446 - accuracy: 0.8103 - val_loss: 1.4357 - val_accuracy: 0.7038\nEpoch 185/200\n328/328 [==============================] - 145s 443ms/step - loss: 0.5294 - accuracy: 0.8170 - val_loss: 1.3613 - val_accuracy: 0.7056\nEpoch 186/200\n328/328 [==============================] - 147s 450ms/step - loss: 0.5293 - accuracy: 0.8196 - val_loss: 1.5163 - val_accuracy: 0.7056\nEpoch 187/200\n328/328 [==============================] - 146s 445ms/step - loss: 0.5600 - accuracy: 0.8084 - val_loss: 1.3993 - val_accuracy: 0.7200\nEpoch 188/200\n328/328 [==============================] - 143s 437ms/step - loss: 0.5530 - accuracy: 0.8146 - val_loss: 1.3434 - val_accuracy: 0.7145\nEpoch 189/200\n328/328 [==============================] - 145s 441ms/step - loss: 0.5259 - accuracy: 0.8192 - val_loss: 1.3685 - val_accuracy: 0.7122\nEpoch 190/200\n328/328 [==============================] - 145s 442ms/step - loss: 0.5313 - accuracy: 0.8190 - val_loss: 1.4649 - val_accuracy: 0.7107\nEpoch 191/200\n328/328 [==============================] - 145s 442ms/step - loss: 0.5387 - accuracy: 0.8115 - val_loss: 1.4685 - val_accuracy: 0.6965\nEpoch 192/200\n328/328 [==============================] - 146s 445ms/step - loss: 0.5389 - accuracy: 0.8148 - val_loss: 1.3850 - val_accuracy: 0.7142\nEpoch 193/200\n328/328 [==============================] - 143s 437ms/step - loss: 0.5204 - accuracy: 0.8202 - val_loss: 1.4484 - val_accuracy: 0.7135\nEpoch 194/200\n328/328 [==============================] - 145s 441ms/step - loss: 0.5305 - accuracy: 0.8191 - val_loss: 1.3378 - val_accuracy: 0.7081\nEpoch 195/200\n328/328 [==============================] - 143s 437ms/step - loss: 0.5174 - accuracy: 0.8202 - val_loss: 1.4312 - val_accuracy: 0.7084\nEpoch 196/200\n328/328 [==============================] - 143s 437ms/step - loss: 0.5242 - accuracy: 0.8175 - val_loss: 1.5026 - val_accuracy: 0.7091\nEpoch 197/200\n328/328 [==============================] - 144s 440ms/step - loss: 0.5272 - accuracy: 0.8156 - val_loss: 1.3337 - val_accuracy: 0.7150\nEpoch 198/200\n328/328 [==============================] - 151s 460ms/step - loss: 0.5334 - accuracy: 0.8137 - val_loss: 1.4696 - val_accuracy: 0.7033\nEpoch 199/200\n328/328 [==============================] - 144s 438ms/step - loss: 0.5219 - accuracy: 0.8212 - val_loss: 1.4860 - val_accuracy: 0.7064\nEpoch 200/200\n328/328 [==============================] - 144s 439ms/step - loss: 0.5065 - accuracy: 0.8266 - val_loss: 1.4128 - val_accuracy: 0.7223\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import save_model\nimport IPython\nimport os","metadata":{"execution":{"iopub.status.busy":"2023-05-31T22:23:29.838536Z","iopub.execute_input":"2023-05-31T22:23:29.838988Z","iopub.status.idle":"2023-05-31T22:23:29.844485Z","shell.execute_reply.started":"2023-05-31T22:23:29.838953Z","shell.execute_reply":"2023-05-31T22:23:29.843284Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Specify the path where you want to save the model in the Kaggle output directory\nsave_path = '/kaggle/working/model_26.h5'\n\n# Save the model to the specified path\nmodel_26.save(save_path)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-31T22:23:29.846251Z","iopub.execute_input":"2023-05-31T22:23:29.846960Z","iopub.status.idle":"2023-05-31T22:23:30.570452Z","shell.execute_reply.started":"2023-05-31T22:23:29.846928Z","shell.execute_reply":"2023-05-31T22:23:30.569197Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(save_path)","metadata":{"execution":{"iopub.status.busy":"2023-05-31T22:37:05.486433Z","iopub.execute_input":"2023-05-31T22:37:05.486834Z","iopub.status.idle":"2023-05-31T22:37:05.493595Z","shell.execute_reply.started":"2023-05-31T22:37:05.486803Z","shell.execute_reply":"2023-05-31T22:37:05.492616Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/model_26.h5","text/html":"<a href='/kaggle/working/model_26.h5' target='_blank'>/kaggle/working/model_26.h5</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"model_26.evaluate(test_data)","metadata":{"execution":{"iopub.status.busy":"2023-05-31T22:23:30.592414Z","iopub.execute_input":"2023-05-31T22:23:30.593268Z","iopub.status.idle":"2023-05-31T22:23:51.224232Z","shell.execute_reply.started":"2023-05-31T22:23:30.593235Z","shell.execute_reply":"2023-05-31T22:23:51.222335Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"124/124 [==============================] - 13s 103ms/step - loss: 1.4128 - accuracy: 0.7223\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"[1.4128338098526, 0.7223207354545593]"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}